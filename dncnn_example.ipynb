{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHdyNNiE8EIf7J5omoBmv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jj132535/DeblurGAN-for-Video-Sharpness/blob/main/dncnn_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1YVO7UpFqig"
      },
      "outputs": [],
      "source": [
        "# Get Dataset from Video File\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import tqdm.notebook as tq\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "\n",
        "# Paths to be configured by the user\n",
        "video_path = \"/content/16-9_CHUU_Strawberry.mp4\"  # Path to the input video file\n",
        "frame_output_path = \"/content/frames\"  # Path to save extracted frames\n",
        "checkpoint_path = \"/content/drive/MyDrive/DNCNN_models/30.tar\"  # Path to the trained model checkpoint\n",
        "result_save_path = \"/content/denoised_frames\"  # Path to save denoised frames\n",
        "output_video_path = \"/content/denoised_video.mp4\"  # Path to save the final denoised video\n",
        "\n",
        "os.makedirs(frame_output_path, exist_ok=True)\n",
        "\n",
        "# Extract frames from video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_filename = os.path.join(frame_output_path, f\"frame_{frame_count:04d}.png\")\n",
        "    cv2.imwrite(frame_filename, frame)\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Noise Transform\n",
        "class NoiseTransform(object):\n",
        "  def __init__(self, size=180, mode=\"training\"):\n",
        "    super(NoiseTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "\n",
        "  def gaussian_noise(self, img):\n",
        "    mean = 0\n",
        "    stddev = 25\n",
        "    noise = torch.zeros(img.size()).normal_(mean, stddev/255.)\n",
        "    return noise\n",
        "\n",
        "  def __call__(self, img):\n",
        "    if self.mode in [\"training\", \"validation\"]:\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor()])\n",
        "      self.noise_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(self.gaussian_noise),\n",
        "      ])\n",
        "      return self.gt_transform(img), self.noise_transform(img)\n",
        "\n",
        "    elif self.mode == \"testing\":\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor()])\n",
        "      return self.gt_transform(img)\n",
        "    else:\n",
        "      return NotImplementedError\n",
        "\n",
        "# Dataloader for Noise Dataset\n",
        "class NoiseDataset(data.Dataset):\n",
        "  def __init__(self, root_path, size):\n",
        "    super(NoiseDataset, self).__init__()\n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.transforms = None\n",
        "    self.examples = [os.path.join(root_path, f) for f in os.listdir(root_path) if f.endswith(\".png\")]\n",
        "\n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = NoiseTransform(self.size, mode)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.examples[idx]\n",
        "    image = Image.open(file_name)\n",
        "\n",
        "    if self.mode == \"testing\":\n",
        "      input_img = self.transforms(image)\n",
        "      sample = {\"img\": input_img, \"file_name\": \"image_%06d.png\" % int(os.path.basename(file_name).split('_')[1].split('.')[0])}\n",
        "    else:\n",
        "      clean, noise = self.transforms(image)\n",
        "      sample = {\"img\": clean, \"noise\": noise}\n",
        "\n",
        "    return sample\n",
        "\n",
        "# Simplified DNCNN network\n",
        "class DNCNN(nn.Module):\n",
        "  def __init__(self, in_planes=3, blocks=17, hidden=64, kernel_size=3, padding=1, bias=False):\n",
        "    super(DNCNN, self).__init__()\n",
        "    self.conv_f = nn.Conv2d(in_channels=in_planes, out_channels=hidden, kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "    self.conv_h = nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "    self.conv_l = nn.Conv2d(in_channels=hidden, out_channels=in_planes, kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "    self.bn = nn.BatchNorm2d(hidden)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    self.hidden_layer = self.mk_hidden_layer(blocks)\n",
        "\n",
        "  def mk_hidden_layer(self, blocks=17):\n",
        "    layers = []\n",
        "    for _ in range(blocks-2):\n",
        "      layers.append(self.conv_h)\n",
        "      layers.append(self.bn)\n",
        "      layers.append(self.relu)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv_f(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.hidden_layer(out)\n",
        "    out = self.conv_l(out)\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Phase\n",
        "\n",
        "os.makedirs(result_save_path, exist_ok=True)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "test_dataset = NoiseDataset(frame_output_path, 128)\n",
        "test_dataset.set_mode(\"testing\")\n",
        "\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "net = DNCNN()\n",
        "\n",
        "if use_cuda:\n",
        "  net.to('cuda')\n",
        "else:\n",
        "  print('CUDA not available, using CPU instead')\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    # Train the model if checkpoint does not exist\n",
        "    print('Checkpoint not found. Training the model...')\n",
        "    train_dataset = NoiseDataset(frame_output_path, 128)\n",
        "    train_dataset.set_mode(\"training\")\n",
        "    train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, eps=1e-08)\n",
        "\n",
        "    if use_cuda:\n",
        "        net.to('cuda')\n",
        "        criterion.to('cuda')\n",
        "\n",
        "    for epoch in range(5):  # Example epoch count\n",
        "        net.train()\n",
        "        for data in train_dataloader:\n",
        "            if use_cuda:\n",
        "                clean, noise = data[\"img\"].to('cuda'), data[\"noise\"].to('cuda')\n",
        "            else:\n",
        "                clean, noise = data[\"img\"], data[\"noise\"]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            noisy_img = clean + noise\n",
        "            pred_noise = net(noisy_img)\n",
        "            loss = criterion(pred_noise, noise)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(net.state_dict(), checkpoint_path)\n",
        "    print(f\"Model saved at {checkpoint_path}\")\n",
        "\n",
        "net.load_state_dict(torch.load(checkpoint_path, map_location='cuda' if use_cuda else 'cpu'))\n",
        "model = nn.DataParallel(net)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Process frames and save denoised frames\n",
        "for i, data in enumerate(tq.tqdm(test_dataloader)):\n",
        "  if use_cuda:\n",
        "    img = data[\"img\"].to('cuda')\n",
        "  else:\n",
        "    img = data[\"img\"]\n",
        "  file_name = data[\"file_name\"]\n",
        "\n",
        "  # The with statement should be aligned with the for loop's body\n",
        "  with torch.no_grad():\n",
        "      out_test = torch.clamp(img - model(img), 0., 1.)\n",
        "  out_img = transforms.ToPILImage()(out_test.squeeze().cpu())\n",
        "  out_img.save(os.path.join(result_save_path, file_name))\n",
        "\n",
        "# Combine denoised frames into video\n",
        "\n",
        "frame_files = sorted([f for f in os.listdir(result_save_path) if f.endswith(\".png\")])\n",
        "first_frame = cv2.imread(os.path.join(result_save_path, frame_files[0]))\n",
        "height, width, layers = first_frame.shape\n",
        "\n",
        "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 60, (width, height))\n",
        "\n",
        "for frame_file in frame_files:\n",
        "    frame = cv2.imread(os.path.join(result_save_path, frame_file))\n",
        "    out.write(frame)\n",
        "\n",
        "out.release()"
      ],
      "metadata": {
        "id": "3_Ruk53JKasU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}