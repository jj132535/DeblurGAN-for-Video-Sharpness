{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOdbSuZPlBLYUwiVMuAdfN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jj132535/DeblurGAN-for-Video-Sharpness/blob/main/DNCNN_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1YVO7UpFqig"
      },
      "outputs": [],
      "source": [
        "# Get Dataset from Video File\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import tqdm.notebook as tq\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "\n",
        "# Paths to be configured by the user\n",
        "video_path = \"/content/16-9_CHUU_Strawberry.mp4\"  # Path to the input video file\n",
        "frame_output_path = \"/content/frames\"  # Path to save extracted frames\n",
        "checkpoint_path = \"/content/drive/MyDrive/DNCNN_models/30.tar\"  # Path to the trained model checkpoint\n",
        "result_save_path = \"/content/denoised_frames\"  # Path to save denoised frames\n",
        "output_video_path = \"/content/denoised_video.mp4\"  # Path to save the final denoised video\n",
        "\n",
        "os.makedirs(frame_output_path, exist_ok=True)\n",
        "\n",
        "# Extract frames from video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_count = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_filename = os.path.join(frame_output_path, f\"frame_{frame_count:04d}.png\")\n",
        "    cv2.imwrite(frame_filename, frame)\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Noise Transform\n",
        "class NoiseTransform(object):\n",
        "  def __init__(self, size=180, mode=\"training\"):\n",
        "    super(NoiseTransform, self).__init__()\n",
        "    self.size = size\n",
        "    self.mode = mode\n",
        "\n",
        "  def gaussian_noise(self, img):\n",
        "    mean = 0\n",
        "    stddev = 25\n",
        "    noise = torch.zeros(img.size()).normal_(mean, stddev/255.)\n",
        "    return noise\n",
        "\n",
        "  def __call__(self, img):\n",
        "    if self.mode in [\"training\", \"validation\"]:\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor()])\n",
        "      self.noise_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(self.gaussian_noise),\n",
        "      ])\n",
        "      return self.gt_transform(img), self.noise_transform(img)\n",
        "\n",
        "    elif self.mode == \"testing\":\n",
        "      self.gt_transform = transforms.Compose([\n",
        "        transforms.Resize((self.size, self.size), interpolation=2),\n",
        "        transforms.ToTensor()])\n",
        "      return self.gt_transform(img)\n",
        "    else:\n",
        "      return NotImplementedError\n",
        "\n",
        "# Dataloader for Noise Dataset\n",
        "class NoiseDataset(data.Dataset):\n",
        "  def __init__(self, root_path, size):\n",
        "    super(NoiseDataset, self).__init__()\n",
        "    self.root_path = root_path\n",
        "    self.size = size\n",
        "    self.transforms = None\n",
        "    self.examples = [os.path.join(root_path, f) for f in os.listdir(root_path) if f.endswith(\".png\")]\n",
        "\n",
        "  def set_mode(self, mode):\n",
        "    self.mode = mode\n",
        "    self.transforms = NoiseTransform(self.size, mode)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.examples[idx]\n",
        "    image = Image.open(file_name)\n",
        "\n",
        "    if self.mode == \"testing\":\n",
        "      input_img = self.transforms(image)\n",
        "      sample = {\"img\": input_img, \"file_name\": \"image_%06d.png\" % int(os.path.basename(file_name).split('_')[1].split('.')[0])}\n",
        "    else:\n",
        "      clean, noise = self.transforms(image)\n",
        "      sample = {\"img\": clean, \"noise\": noise}\n",
        "\n",
        "    return sample\n",
        "\n",
        "# Simplified DNCNN network\n",
        "class DNCNN(nn.Module):\n",
        "  def __init__(self, in_planes=3, blocks=17, hidden=64, kernel_size=3, padding=1, bias=False):\n",
        "    super(DNCNN, self).__init__()\n",
        "    self.conv_f = nn.Conv2d(in_channels=in_planes, out_channels=hidden, kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "    self.conv_h = nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "    self.conv_l = nn.Conv2d(in_channels=hidden, out_channels=in_planes, kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "    self.bn = nn.BatchNorm2d(hidden)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    self.hidden_layer = self.mk_hidden_layer(blocks)\n",
        "\n",
        "  def mk_hidden_layer(self, blocks=17):\n",
        "    layers = []\n",
        "    for _ in range(blocks-2):\n",
        "      layers.append(self.conv_h)\n",
        "      layers.append(self.bn)\n",
        "      layers.append(self.relu)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv_f(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.hidden_layer(out)\n",
        "    out = self.conv_l(out)\n",
        "    return out\n",
        "\n"
      ]
    }
  ]
}